# -*- coding: utf-8 -*-
"""Data Analysis 510.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RmKYjsmnXsWst0p5zU8jq5boxQ7n47hc
"""

import urllib.request
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import os
from statsmodels.stats.power import TTestIndPower

path = Path()

files = {
    "EIA930_BALANCE_2025_Jan_Jun.csv": "https://www.eia.gov/electricity/gridmonitor/sixMonthFiles/EIA930_BALANCE_2025_Jan_Jun.csv",
    "EIA930_BALANCE_2024_Jul_Dec.csv": "https://www.eia.gov/electricity/gridmonitor/sixMonthFiles/EIA930_BALANCE_2024_Jul_Dec.csv",
    "EIA930_Reference_Tables.xlsx": "https://www.eia.gov/electricity/930-content/EIA930_Reference_Tables.xlsx"
}

# Download each file
for key, value in files.items():
    filename = path / key
    url = value
    # If the file does not already exist in the directory, download it
    if not os.path.exists(filename):
        urllib.request.urlretrieve(url, filename)
#%% md
# ## Read Data
#
# Our first step is to understand the data and read the rows and columns that exist. We need to explore and understand what all of the columns actually mean before we can work with the data.
#%%
df1 = pd.read_csv("EIA930_BALANCE_2024_Jul_Dec.csv")
df2 = pd.read_csv("EIA930_BALANCE_2025_Jan_Jun.csv")

# Concat both dataframes
df = pd.concat([df1, df2], ignore_index=True)

df["UTC Time at End of Hour"] = pd.to_datetime(df["UTC Time at End of Hour"])

print(df["UTC Time at End of Hour"].min(), "to", df["UTC Time at End of Hour"].max())

print(df.columns)

df.head(10)

"""We can see that there are sources of energy that are not renewable energy sources. We took out non-renewable energy sources and kept the renewable energy sources above.

Assumption: We assumed that we could leave in unknown and other for now and take it out later if it was an invalid assumption.
"""

columns = ['Net Generation (MW) from Nuclear (Adjusted)',
'Net Generation (MW) from Hydropower Excluding Pumped Storage (Adjusted)',
'Net Generation (MW) from Pumped Storage  (Adjusted)',
'Net Generation (MW) from Solar without Integrated Battery Storage (Adjusted)',
'Net Generation (MW) from Solar witho Integrated Battery Storage (Adjusted)',
'Net Generation (MW) from Wind without Integrated Battery Storage (Adjusted)',
'Net Generation (MW) from Wind with Integrated Battery Storage (Adjusted)',
'Net Generation (MW) from Geothermal (Adjusted)']

adjusted_generation_by_ba = df2.set_index('Data Date')

# Select the columns and convert them to numeric, coercing errors
adjusted_generation_by_ba = adjusted_generation_by_ba[columns].apply(pd.to_numeric, errors='coerce')

#display(adjusted_generation_by_ba.head())
print(type(adjusted_generation_by_ba['Net Generation (MW) from Nuclear (Adjusted)']))

df_time_series = df.set_index('UTC Time at End of Hour')

# Select the columns
df_time_series = df_time_series['Net Generation (MW) from Pumped Storage  (Adjusted)']

# Plot all columns with color coding and a legend
ax = df_time_series.plot(figsize=(15, 8))
ax.set_ylabel('Net Generation (MW)')
ax.set_title('Net Generation from Renewable Energy Sources (Adjusted) from July 2024 to June 2025')
ax.legend(title='Renewable Energy Source', loc='best')
plt.gcf().autofmt_xdate()   # rotate and format date labels
plt.tight_layout() # Adjust layout to prevent legend from overlapping
plt.show()

adjusted_generation_by_ba = df.groupby(["Balancing Authority", "Data Date"])[columns].mean()
display(adjusted_generation_by_ba.head())

mean_generation_across_days = adjusted_generation_by_ba.groupby("Balancing Authority").mean()
display(mean_generation_across_days.head(62))

# Just to double check and make sure that we are capturing all the Balancing authorities

unique_balancing_authorities = df['Balancing Authority'].unique()
print((len(unique_balancing_authorities)))

mean_generation_across_days['Net Generation (MW) from Renewable Energy Source (Adjusted)'] = mean_generation_across_days[columns].sum(axis=1)
mean_generation_across_days = mean_generation_across_days.loc[:, ['Net Generation (MW) from Renewable Energy Source (Adjusted)']]
display(mean_generation_across_days.head())



# Parameters
effect_size = 1.2
alpha = 0.05
power = 0.80

# Power analysis
analysis = TTestIndPower()
sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='larger')
print(sample_size)

"""We are conducting a two-sampled t-test. We need to calculate the following from our data:
1. Mean of Group A ($\bar{x}_A$)
2. Mean of Group B ($\bar{x}_B$)
3. Standard Deviation of Group A ($s_A$)
4. Standard Deviation of Group B ($s_B$)
5. Sample Size of Group A ($n_A$)
6. Sample Size of Group B ($n_B$)

Our two groups are:



1.   BA's without Publicly Available Microsoft Data Centers
2.   BA's with Publicly Available Microsoft Data Centers

See below for the two groups of BA's
"""

file_path = 'Balancing Authority with Microsoft Azure Data Centers.xlsx'
df_with_data_centers = pd.read_excel(file_path)
len(df_with_data_centers)

# These are all unique BA's with Data Centers
balancing_authorities_with_data_centers = df_with_data_centers['BA Initials / Acronym'].unique().tolist()
print(balancing_authorities_with_data_centers)

#These are all the unique BA's without Data Centers
balancing_authorities_without_data_centers = [ba for ba in unique_balancing_authorities if ba not in balancing_authorities_with_data_centers]
print(balancing_authorities_without_data_centers)

# Now we check to make sure that both add up to 62.
print(len(balancing_authorities_without_data_centers))
print(len(balancing_authorities_with_data_centers))

# Now we need to split up the dataset so that it has Group A as the Balancing Authorities with Data Centers and Group B as the BAs without Data Centers
Group_A = mean_generation_across_days.loc[balancing_authorities_with_data_centers]
Group_B = mean_generation_across_days.loc[balancing_authorities_without_data_centers]

# Now I need the mean for group A and B
groupa_mean = Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].mean()
groupb_mean = Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].mean()

print(f'this is the mean for group A (with data centers) {groupa_mean:.2f}')
print(f'this is the mean for group B (without data center) {groupb_mean:.2f}')

# Now I need the std dev for group A and B
groupa_std_dev = Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].std()
groupb_std_dev = Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].std()
print(groupa_std_dev)
print(groupb_std_dev)

# And we already know the Sample Size for group A and B
n_group_a = len(Group_A)
n_group_b = len(Group_B)

# We also have to find the variance for each sample size
var_group_a = groupa_std_dev**2
var_group_b = groupb_std_dev**2
print(f'this is the variance for group A (with Microsoft data centers) {var_group_a:.2f}')
print(f'this is the variance for group B (without Microsoft data center) {var_group_b:.2f}')

"""At this point we are trying to find the t-statistic for comparing two independent groups (BA's with Data Centers aka group A and BA's without Data Centers aka group B).

It makes a few assumptions though so we need to validate those assumptions first to see if we should use Welch's t-test

1. Independence
2. Normality
3. Continuous Data

Unlike the Student's t-test, it does not assume that variances of the two groups are equal. And based on our findings above, we know that that is true.  Now to test for the assumptions.

1. Independence. We think this is a valid assumption because the *observations* within each group were collected independently although the samples themselves were selected based on whether the BA's had Data Centers in them. The observations were not related in any way since BA giving power to one data center had no impact on whether another BA gave power to a different data center.

2. Normality. While the data is not completely normally distributed it is approximately normally distributed which is still valid because the Welch's t-test should be slightly robust to violations of this assumptions. See the plot below for the Q plot that validates this assumption.

3. Continuous Data. Continuous data is a type of quantitative data that can take any value within a given range or interval. Since it is measurable, it has infinite possibilities, and is expressed as decimals, we believe that this is continuous data. Additionally it is not categorical/discrete data because discrete data has specific, separate values and categorical data has different categories, of which this data has neither.



I used Gemini on 21 2052 OCT 25. I did use Gemini to help me come up with the explanations of the validations of these assumptions. Specifically the definitions of continuous data, discrete data. I also used it to validate my explanations for why I thought these assumptions were correct. I also used it to help me come up with the syntax for the data. I came up with the methodology myself and the steps that we needed to take. I wrote almost all comments to help understand the code myself.
"""

# Test the normality of group A and B using a Q plot

import scipy.stats as stats
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
import statsmodels.api as sm

# Create a figure and a set of subplots for Q-Q plots
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

legend_handles = [
    Line2D([0], [0], marker='o', color='w', label='True Normal Distribution',
           markerfacecolor='red', markeredgecolor='red', markersize=8, linestyle='None'),
    Line2D([0], [0], marker='o', color='w', label='My Data',
           markerfacecolor='blue', markeredgecolor='blue', markersize=8, linestyle='None')
]

# Create Q-Q plot for Group A
sm.qqplot(Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), line='s', ax=axes[0])
axes[0].set_title('Q-Q Plot for Group A')
axes[0].legend(handles=legend_handles, loc='best')

# Create Q-Q plot for Group B
sm.qqplot(Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), line='s', ax=axes[1])
axes[1].set_title('Q-Q Plot for Group B')
axes[1].legend(handles=legend_handles, loc='best')

# Display the plots
plt.tight_layout()

plt.show()

# Perform Shapiro-Wilk test for Group A
shapiro_test_a = stats.shapiro(Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna())
print(f'Shapiro-Wilk test for Group A: Statistic={shapiro_test_a.statistic:.4f}, p-value={shapiro_test_a.pvalue:.4f}')

# Perform Shapiro-Wilk test for Group B
shapiro_test_b = stats.shapiro(Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna())
print(f'Shapiro-Wilk test for Group B: Statistic={shapiro_test_b.statistic:.4f}, p-value={shapiro_test_b.pvalue:.4f}')

# Perform Kolmogorov-Smirnov test for Group A
ks_test_a = stats.kstest(Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), 'norm')
print(f'Kolmogorov-Smirnov test for Group A: Statistic={ks_test_a.statistic:.4f}, p-value={ks_test_a.pvalue:.4f}')

# Perform Kolmogorov-Smirnov test for Group B
ks_test_b = stats.kstest(Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), 'norm')
print(f'Kolmogorov-Smirnov test for Group B: Statistic={ks_test_b.statistic:.4f}, p-value={ks_test_b.pvalue:.4f}')

"""The Q-Q plot, Shapiro-Wilk and Kolmogorov-Smirnov tests are statistical tests used to assess whether a dataset is normally distributed. After three different tests, we can conclude that the data is not normally distributed.

For the Shapiro-Wilk test:
- The null hypothesis is that the data is drawn from a normal distribution.
- The alternative hypothesis is that the data is not drawn from a normal distribution.

For the Kolmogorov-Smirnov test:
- The null hypothesis is that the data follows a specified distribution (in this case, a normal distribution).
- The alternative hypothesis is that the data does not follow the specified distribution.

In both tests, a small p-value (typically less than the significance level, e.g., 0.05) indicates that you should reject the null hypothesis and conclude that the data is not normally distributed.

Looking at the output:
- **Group A (with data centers):** The Shapiro-Wilk test has a p-value of 0.0511, which is slightly above the typical significance level of 0.05. This suggests that we might not have enough evidence to reject the null hypothesis of normality for Group A, although it's close to the threshold. The Kolmogorov-Smirnov test for Group A has a p-value of 0.0000, which strongly suggests that the data is *not* normally distributed. These two tests give conflicting results, which can happen, especially with smaller sample sizes.

- **Group B (without data centers):** Both the Shapiro-Wilk test (p-value = 0.0000) and the Kolmogorov-Smirnov test (p-value = 0.0000) have very small p-values. This provides strong evidence to reject the null hypothesis of normality for Group B.

Based on these test results, especially for Group B, the assumption of normality for a standard independent samples t-test is not met. However, as you mentioned in the previous markdown cell, the Welch's t-test is more robust to violations of the normality assumption, particularly when sample sizes are different and variances are unequal (which we observed earlier). Therefore, proceeding with Welch's t-test is a reasonable approach given these results.

**DO ANOTHER test and explain the reasoning for the power AND Flp it**

This plot is a Q-Q plot, which stand for a Quantile-Quantile plot. It is used to visually check if your data comes from a specific probability distribution. In this case, a normal, gaussian distribution. Since this is completely new and we haven't learned this I incldued the 4 main steps:

1. It sorts through the data, sorting your data points from smallest to largest.
2. Then it calculates quantiles for your sorted data. Remember (I forget this, which is why I am adding it here), the 25th quantile, or 25th percentile, is the value below which 25% of the data falls.
3. It then calculates the theretical quantiles for the same points, assuming that my data perfectly followed a normal distribution.
4. Then it plots the the sample quantiles on one axis and the theoretical quantiles on the other axis. This makes sense because if it does follow a normal distribution, then technically it should just be a straight line with a linearly increasing slope, as shown on the graph above. This groahs calculates and then plots the theoretical Z-score for each data point's position against the actual data value at that percentile.

The blue dots represent the quantiles of the data. The red line is the reference line showing where the data points would fall if they were perfectly normally distributed. As you can see group A is approximately normally distributed and group B is a little less approximately normally distributed. Nevertheless, since the variances are different and it followsd the assumptions, we decide to move forward with Welch's T-statistic. And since we have the hypothesis, and sample statistics, we move forward to actually just calculating the statistic.

The results from Welch's t-test are invalid because the data is not normally distributed but we still left the code in here
"""

# Calculate Welch's t-statistic
t_statistic = (groupa_mean - groupb_mean) / ((var_group_a / n_group_a) + (var_group_b / n_group_b))**0.5
print(f'The t-statistic is {t_statistic:.2f}')

# Now calculate the degrees of freedom using the Welch-Satterthwaite equation.
degrees_of_freedom = ((var_group_a / n_group_a) + (var_group_b / n_group_b))**2 / (((var_group_a / n_group_a)**2 / (n_group_a - 1)) + ((var_group_b / n_group_b)**2 / (n_group_b - 1)))
print(f'The degrees of freedom are {degrees_of_freedom:.0f}')

# Now I need to determine the p-value
import scipy.stats as stats
p_value = 1 - stats.t.cdf(t_statistic, df=degrees_of_freedom)
print(f'The p-value is {p_value:.4f}')

"""To Determine which df we needed to use, we took a look at all the different degrees of freedom. The Welch-Sattertwaithe equation has three assumptions if met, we should be using:



1. We have independent samples.
2. We are using the sample variance ($s^2$) from each sample.
3. Our statistic itself is a weighted sum of those variances.

Source: https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation


Since all of these are true we used the Welch-Satterthwaite equation tpo determine the degrees of freedom.

As seen above the p-value is .0160. We had previously determined our alpha to be .05. Since .0160 is less than .05, we reject the null hypothesis that there is no difference in the mean of renewable energy sources for Balancing Authorities with known Microsoft Azure Data Centers compared to the Balancing Authorities without known Microsoft Azure Data Centers.

This means that there is a statistically significant difference in the Balancing Authorities with known Microsoft Azure Data Centers compared to Balancing Authorities without known Microsoft Azure Data Centers. From this we can identify this needle in a haystack problem to develop a better heuristic in understanding the likelihood of a Microsoft Data Center being in a Balancing Authority.

Assumptions:

1. We assume that the assumption of normal distribution is still valid for group B because it could perceived as approximately normal but also because the Welch's t-test should still be robust to that.
2. We also assume that a sample size of 10 is good enough for two reasons. First we dont have other BAs with Microsoft Data Centers. Second, Welch's t-statistic is robust to approximations in normally distributed data and the data is normally distributed.

This whole thing (Welch's t-test) is invalid because as shown above, the data is not distributed.

Future Steps

1. Implement a version of a fourier transform to figure out which renewable energy sources Microsoft uses.

This is the Mann-Whitney U test that we had to conduct based on the fact that the assumption of normality was violated for Welch's t-test.
"""

from scipy.stats import mannwhitneyu

# Perform the Mann-Whitney U test
statistic, p_value_mw = mannwhitneyu(Group_A['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), Group_B['Net Generation (MW) from Renewable Energy Source (Adjusted)'].dropna(), alternative='greater')

print(f"Mann-Whitney U statistic: {statistic:.4f}")
print(f"Mann-Whitney U p-value: {p_value_mw:.4f}")

"""The Mann-Whitney U test is a non-parametric test that assesses whether two independent samples are from the same distribution. It is often used as an alternative to the independent samples t-test when the assumption of normality is not met, which is the case for our data (especially Group B).

Here are the results:
- **Mann-Whitney U statistic:** This is the test statistic. It represents the number of times a value from Group A is greater than a value from Group B (or vice-versa). Our calculated statistic is 458.0000.
- **Mann-Whitney U p-value:** This is the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from the data, assuming the null hypothesis is true. The null hypothesis for the Mann-Whitney U test is that the distributions of the two groups are the same. Our calculated p-value is 0.0001.

Interpretation:
With a p-value of 0.0002, which is much less than our chosen significance level of 0.05, we reject the null hypothesis. This means there is a statistically significant difference in the distribution of renewable energy generation between Balancing Authorities with known Microsoft Azure Data Centers (Group A) and those without known Microsoft Azure Data Centers (Group B).

This finding aligns with the results of the Welch's t-test and further supports the conclusion that there is a difference in renewable energy generation between these two groups of Balancing Authorities.

Things to check with Dr. Bent.

1. We definitely reject the null I think but can you just validate that this is correct?
2. your thoughts on whether you think it is a normal distribution for grouop B and whether we can still use Welch's t-test.

### Citations

I used Gemini on 21 2149 OCT 2025. I used it to help me refine my understanding of concepts like the Q-Q plots. I also used it to figure out that I needed to calculate my degrees of freedom using the Welch-Satterthwaite equation. I didn't even know that was a thing. I used it to help with almost all my coding. But I did come up with everything that I needed to do on my own and wrote most of the comments by myself. I typically told Gemini  exactly what I needed for each specific line rather than doing the whole thing for me.

Check seasonality

Check if Adjusted and demand factoring in BA to BA interchange

Check the df
"""
